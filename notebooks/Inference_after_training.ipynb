{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the model is stable and reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import chess\n",
    "import chess.svg\n",
    "import hydra\n",
    "import rootutils\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "rootutils.setup_root(os.path.abspath(\".\"), indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.utils.chess_utils import ChessBoard, ChessData, ChessGame, ChessMove\n",
    "\n",
    "\n",
    "def get_correct_state_dict(state_dict):\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        name = k.replace(\"net.\", \"\")  # remove \"net.\" from the keys\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def get_tempfix_for_torch(ckpt):\n",
    "    \"\"\"TODO(mai0313): remove _orig_mod. from the state_dict due to pytorch issue #101107.\n",
    "\n",
    "    Ref: https://discuss.pytorch.org/t/how-to-save-load-a-model-with-torch-compile/179739/2\n",
    "         https://github.com/pytorch/pytorch/issues/101107#issuecomment-1542688089\n",
    "    In short, when you train a model with torch.compile, it will add _orig_mod. to the state_dict, which is not what we need;\n",
    "    So we just simply remove it.\n",
    "    \"\"\"\n",
    "    new_dict = OrderedDict()\n",
    "    for k, v in ckpt[\"state_dict\"].items():\n",
    "        name = k.replace(\"_orig_mod.\", \"\")\n",
    "        new_dict[name] = v\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def load_model_from_path(log_directory):\n",
    "    ckpt_path = f\"{log_directory}/checkpoints/last.ckpt\"\n",
    "    model_config = OmegaConf.load(f\"{log_directory}/.hydra/config.yaml\")\n",
    "    compile_option = model_config.model.compile\n",
    "    if compile_option:\n",
    "        model_instance = hydra.utils.instantiate(model_config.model)\n",
    "        checkpoint = torch.load(ckpt_path)\n",
    "        fixed_state_dict = get_tempfix_for_torch(checkpoint)\n",
    "        model_instance.load_state_dict(fixed_state_dict)\n",
    "    else:\n",
    "        model_instance = hydra.utils.instantiate(model_config.model)\n",
    "        model_instance.load_from_checkpoint(ckpt_path)\n",
    "    return model_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter the path of your logs\n",
    "\n",
    "- `logs_path = '../logs/2020-05-20_15-00-00'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory_v1 = \"../logs/chess_md2/runs/2023-10-01_22-54-38\"\n",
    "log_directory_v2 = \"../logs/chess_md2/runs/2023-10-01_22-54-38\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Play\n",
    "\n",
    "- AI vs AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = load_model_from_path(log_directory_v1)\n",
    "ChessGame(white_model = model_instance, gpu = True).self_play(gui = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model vs Stockfish\n",
    "\n",
    "- This function allows you to see if your model is better than Stockfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = load_model_from_path(log_directory_v1)\n",
    "ChessGame(model_instance, True).model_vs_stockfish(gui = True, stockfish_path = \"../stockfish_linux/stockfish-ubuntu-x86-64-avx2\", cpu_nums = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Play Version 2\n",
    "\n",
    "- This is for model 1 vs model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = load_model_from_path(log_directory_v1)\n",
    "model_instance_2 = load_model_from_path(log_directory_v2)\n",
    "\n",
    "ChessGame(model_instance, False).model_vs_model(model_instance_2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play with AI\n",
    "\n",
    "- You v.s. AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = load_model_from_path(log_directory_v1)\n",
    "ChessGame(model_instance, True).play_against_ai(gui = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve a chess puzzle\n",
    "\n",
    "- Given a chessboard, find the best move for white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = load_model_from_path(log_directory_v1)\n",
    "\n",
    "board = chess.Board(\"8/1K6/8/1P6/2rpP3/2P5/8/8 b - - 0 1\")\n",
    "best_move = ChessGame(model_instance, True).solve_puzzle(board = board, gui = True)\n",
    "print(f\"模型推薦的移動是：{best_move}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
